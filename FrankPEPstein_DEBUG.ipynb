{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61266d76",
   "metadata": {},
   "source": [
    "\n",
    "# FrankPEPstein: Interactive Peptide Fragment Design\n",
    "\n",
    "This notebook implements the FrankPEPstein pipeline for designing peptide fragments binding to a specific protein pocket.\n",
    "\n",
    "**Steps:**\n",
    "1.  Setup & Dependencies\n",
    "2.  Input Data (Receptor)\n",
    "3.  Pocket Selection\n",
    "4.  Fragment Generation & Ranking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a5d83",
   "metadata": {},
   "source": [
    "## 0. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title 0.1 Install CondaColab (Running this will restart the session)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Helper to suppress output\n",
    "class SuppressStdout:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "try:\n",
    "    import condacolab\n",
    "    with SuppressStdout():\n",
    "        condacolab.check()\n",
    "except ImportError:\n",
    "    print(\"Installing CondaColab...\")\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    with SuppressStdout():\n",
    "        condacolab.install()\n",
    "print(\"CondaColab installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec929956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title 0.2 Install Dependencies & Setup Tools\n",
    "#@markdown This cell clones the repository and creates the 'FrankPEPstein' environment with Python 3.10.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# --- 1. Clone Repository ---\n",
    "if not os.path.exists(\"FrankPEPstein\"):\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone https://github.com/Joacaldog/FrankPEPstein.git\n",
    "else:\n",
    "    print(\"Repository already exists.\")\n",
    "\n",
    "# --- 2. Create Conda Environment 'FrankPEPstein' ---\n",
    "print(\"Creating 'FrankPEPstein' environment with Python 3.10 (this may take a few minutes)...\")\n",
    "# Create environment with all dependencies including Modeller\n",
    "!mamba create -n FrankPEPstein -q -y -c conda-forge -c salilab openbabel biopython fpocket joblib tqdm py3dmol vina python=3.10 salilab::modeller\n",
    "\n",
    "# --- 3. Configure Path for Colab Usage ---\n",
    "# Since Colab runs on the 'base' kernel, we need to manually add the new env to paths\n",
    "env_path = \"/usr/local/envs/FrankPEPstein\"\n",
    "site_packages = f\"{env_path}/lib/python3.10/site-packages\"\n",
    "\n",
    "if site_packages not in sys.path:\n",
    "    sys.path.append(site_packages)\n",
    "\n",
    "# Add binary path for tools like fpocket, obabel, etc.\n",
    "os.environ['PATH'] = f\"{env_path}/bin:\" + os.environ['PATH']\n",
    "\n",
    "print(f\"Environment 'FrankPEPstein' created and configured.\")\n",
    "\n",
    "# --- PATCH: Update notebook_utils.py with local changes ---\n",
    "# This ensures we use the latest path logic without needing a git push\n",
    "patched_utils_content = r'''import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "def configure_modeller(license_key='MODELIRANJE', repo_dir='FrankPEPstein'):\n",
    "    \"\"\"\n",
    "    Configures Modeller by locating the config.py file in the installation\n",
    "    and replacing the license key placeholder with the provided key.\n",
    "    \"\"\"\n",
    "    # Template location in the repo\n",
    "    template_config = os.path.join(repo_dir, \"utilities/config.py\")\n",
    "    \n",
    "    # Try using python import to find the location\n",
    "    dest_config = None\n",
    "    try:\n",
    "        import modeller\n",
    "        modeller_path = os.path.dirname(modeller.__file__)\n",
    "        candidate = os.path.join(modeller_path, \"config.py\")\n",
    "        if os.path.exists(candidate):\n",
    "            dest_config = candidate\n",
    "    except Exception:\n",
    "        # Modeller raises an error on import if not configured, which is expected.\n",
    "        # We just want to find where it is installed.\n",
    "        pass\n",
    "\n",
    "    # Fallback to search if import finding failed\n",
    "    if not dest_config:\n",
    "        possible_paths = [\n",
    "            f\"{sys.prefix}/lib/modeller-*/modlib/modeller/config.py\", # Standard standalone install\n",
    "            f\"{sys.prefix}/lib/python*/site-packages/modeller/config.py\", # Site-packages install\n",
    "            f\"{sys.prefix}/pkgs/modeller-*/lib/modeller-*/modlib/modeller/config.py\", # Conda pkgs cache structure\n",
    "            \"/usr/local/envs/FrankPEPstein/lib/modeller-*/modlib/modeller/config.py\" # Targeted Conda Environment\n",
    "        ]\n",
    "        \n",
    "        dest_config_paths = []\n",
    "        for pattern in possible_paths:\n",
    "            found = glob.glob(pattern)\n",
    "            dest_config_paths.extend(found)\n",
    "        \n",
    "        if dest_config_paths:\n",
    "            dest_config = dest_config_paths[0]\n",
    "\n",
    "    \n",
    "    if dest_config and os.path.exists(template_config):\n",
    "        print(f\"Found modeller config at: {dest_config}\")\n",
    "        print(f\"Using template {template_config} to update {dest_config}\")\n",
    "        \n",
    "        with open(template_config, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Replace placeholder 'MODELIRANJE' with actual key\n",
    "        new_content = content.replace(\"'MODELIRANJE'\", f\"'{license_key}'\")\n",
    "        \n",
    "        with open(dest_config, 'w') as f:\n",
    "            f.write(new_content)\n",
    "        print(\"Modeller configured successfully.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Error: Modeller config destination ({dest_config}) or template ({template_config}) not found.\")\n",
    "        return False\n",
    "\n",
    "def get_pocket_box(pdb_file):\n",
    "    \"\"\"\n",
    "    Calculates the center and size of a box surrounding the atoms in the given PDB file.\n",
    "    Adds a buffer of 5.0 units to the size.\n",
    "    \"\"\"\n",
    "    import Bio.PDB\n",
    "    parser = Bio.PDB.PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"pocket\", pdb_file)\n",
    "    coords = []\n",
    "    for atom in structure.get_atoms():\n",
    "        coords.append(atom.get_coord())\n",
    "    \n",
    "    if not coords:\n",
    "        return None, None\n",
    "\n",
    "    min_coord = [min([c[i] for c in coords]) for i in range(3)]\n",
    "    max_coord = [max([c[i] for c in coords]) for i in range(3)]\n",
    "    \n",
    "    center = [(min_coord[i] + max_coord[i]) / 2 for i in range(3)]\n",
    "    size = [(max_coord[i] - min_coord[i]) + 5.0 for i in range(3)] # Add buffer\n",
    "    return center, size\n",
    "\n",
    "def patch_scripts(scripts_dir, path_replacements):\n",
    "    \"\"\"\n",
    "    Iterates through .py files in scripts_dir and applies string replacements.\n",
    "    \"\"\"\n",
    "    print(\"Patching scripts...\")\n",
    "    count = 0\n",
    "    for script_name in os.listdir(scripts_dir):\n",
    "        if script_name.endswith(\".py\"):\n",
    "            full_path = os.path.join(scripts_dir, script_name)\n",
    "            with open(full_path, 'r') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            original_content = content\n",
    "            for old, new in path_replacements.items():\n",
    "                content = content.replace(old, new)\n",
    "            \n",
    "            # Additional patches for command calls\n",
    "            content = content.replace(\"vina\", \"vina\") \n",
    "            \n",
    "            if content != original_content:\n",
    "                with open(full_path, 'w') as f:\n",
    "                    f.write(content)\n",
    "                print(f\"Patched {script_name}\")\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def setup_external_tools(drive_ids=None):\n",
    "    \"\"\"\n",
    "    Sets up external tools (ADFR, Click, DB).\n",
    "    If drive_ids is provided, downloads missing files from Google Drive.\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    \n",
    "    # Ensure gdown is installed\n",
    "    try:\n",
    "        import gdown\n",
    "    except ImportError:\n",
    "        print(\"Installing gdown...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"], check=True)\n",
    "        import gdown\n",
    "\n",
    "    base_dir = \"FrankPEPstein\"\n",
    "    # Adjust base_dir if we are running from root vs inside scripts?\n",
    "    # The utils assume repo_dir='FrankPEPstein' usually implies subfolder.\n",
    "    # But if looking for \"utilities\", it usually expects to find them relative to CWD?\n",
    "    # Let's check config.\n",
    "    # In notebook setup: repo_path = os.path.abspath(\"FrankPEPstein\").\n",
    "    # If we run cell_01_setup.py from FrankPEPstein root, base_dir \"FrankPEPstein\" might be wrong if we are IN it?\n",
    "    # notebook_utils.py:\n",
    "    #   configure_modeller default repo_dir='FrankPEPstein'.\n",
    "    #   BUT when running locally in the repo, 'FrankPEPstein' folder DOES NOT EXIST inside 'FrankPEPstein'.\n",
    "    #   The repo IS the cwd.\n",
    "    #   When cloning in Colab: cwd is /content/, repo is /content/FrankPEPstein.\n",
    "    #   So 'FrankPEPstein/utilities' is correct there.\n",
    "    #   But LOCALLY, if I am in ~/FrankPEPstein/, 'FrankPEPstein/utilities' does not exist. 'utilities' exists.\n",
    "    \n",
    "    # I need to handle this path difference!\n",
    "    \n",
    "    if os.path.exists(\"utilities\"):\n",
    "        # We are likely INSIDE the repo root (Local execution)\n",
    "        base_dir = \".\"\n",
    "    elif os.path.exists(\"FrankPEPstein/utilities\"):\n",
    "        # We are likely in parent dir (Colab default)\n",
    "        base_dir = \"FrankPEPstein\"\n",
    "    else:\n",
    "        # Fallback or create?\n",
    "        base_dir = \"FrankPEPstein\" # Default to colab behavior for safety, or create it.\n",
    "\n",
    "    utilities_dir = os.path.join(base_dir, \"utilities\")\n",
    "    db_dir = os.path.join(base_dir, \"DB\")\n",
    "    \n",
    "    os.makedirs(utilities_dir, exist_ok=True)\n",
    "    os.makedirs(db_dir, exist_ok=True)\n",
    "\n",
    "    # File definitions\n",
    "    files = {\n",
    "        \"adfr\": {\n",
    "            \"path\": os.path.join(utilities_dir, \"ADFRsuite_x86_64Linux_1.0.tar.gz\"),\n",
    "            \"id_key\": \"adfr_id\",\n",
    "            \"extract_cmd\": f\"tar -xzf {{}} -C {utilities_dir}\",\n",
    "            \"bin_path\": os.path.join(os.path.abspath(utilities_dir), \"ADFRsuite_x86_64Linux_1.0/bin\") \n",
    "        },\n",
    "        \"click\": {\n",
    "            \"path\": os.path.join(utilities_dir, \"Click.tar.gz\"),\n",
    "            \"id_key\": \"click_id\",\n",
    "            \"extract_cmd\": f\"tar -xzf {{}} -C {utilities_dir}\",\n",
    "            \"bin_path\": os.path.join(os.path.abspath(utilities_dir), \"Click/bin\")\n",
    "        },\n",
    "        \"db\": {\n",
    "            \"path\": os.path.join(db_dir, \"minipockets_surface80_winsize3_size3_curated-db.tar.gz\"),\n",
    "            \"id_key\": \"db_id\",\n",
    "            \"extract_cmd\": f\"tar -xzf {{}} -C {db_dir}\"\n",
    "        },\n",
    "        \"dict\": {\n",
    "            \"path\": os.path.join(db_dir, \"reduce_wwPDB_het_dict.tar.gz\"), \n",
    "            \"id_key\": \"dict_id\",\n",
    "            \"extract_cmd\": f\"tar -xzf {{}} -C {db_dir}\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if drive_ids is None:\n",
    "        drive_ids = {}\n",
    "\n",
    "    for name, info in files.items():\n",
    "        if not os.path.exists(info[\"path\"]):\n",
    "            # Check if we have an ID to download\n",
    "            file_id = drive_ids.get(info[\"id_key\"])\n",
    "            if file_id:\n",
    "                print(f\"Downloading {name}...\")\n",
    "                url = f'https://drive.google.com/uc?id={file_id}'\n",
    "                gdown.download(url, info[\"path\"], quiet=False)\n",
    "            else:\n",
    "                pass\n",
    "                # print(f\"WARNING: {name} file not found and no ID provided for download.\")\n",
    "        \n",
    "        # Extract if exists\n",
    "        # Check extraction marker? Or just checking if extracted dir exists?\n",
    "        # For tarballs, usually they extract a folder.\n",
    "        # ADFR -> ADFRsuite_x86_64Linux_1.0\n",
    "        # Click -> Click\n",
    "        # DB -> minipockets (maybe?)\n",
    "        \n",
    "        # Simple heuristic: If tarball exists, run extract.\n",
    "        # Ideally check if destination exists.\n",
    "        \n",
    "        should_extract = False\n",
    "        if os.path.exists(info[\"path\"]):\n",
    "             should_extract = True\n",
    "             # Optimization: Check if bin_path exists?\n",
    "             if \"bin_path\" in info and os.path.exists(info[\"bin_path\"]):\n",
    "                 should_extract = False\n",
    "        \n",
    "        if should_extract:\n",
    "            print(f\"Extracting {name}...\")\n",
    "            subprocess.run(info[\"extract_cmd\"].format(info[\"path\"]), shell=True, check=True)\n",
    "            \n",
    "        # Add to PATH if needed\n",
    "        if \"bin_path\" in info and os.path.exists(info[\"bin_path\"]):\n",
    "            os.environ['PATH'] += f\":{info['bin_path']}\"\n",
    "            if name == \"click\":\n",
    "                    subprocess.run(f\"chmod +x {info['bin_path']}/click\", shell=True)\n",
    "            print(f\"Added {name} to PATH: {info['bin_path']}\")\n",
    "    \n",
    "    # Handle dictionary txt\n",
    "    dict_txt = os.path.join(db_dir, \"reduce_wwPDB_het_dict.txt\")\n",
    "    if os.path.exists(dict_txt):\n",
    "        print(\"Dictionary txt found.\")\n",
    "    else:\n",
    "        print(\"WARNING: reduce_wwPDB_het_dict.txt not found (maybe inside another folder after extraction?)\")\n",
    "\n",
    "'''\n",
    "\n",
    "os.makedirs(\"FrankPEPstein/scripts\", exist_ok=True)\n",
    "with open(\"FrankPEPstein/scripts/notebook_utils.py\", \"w\") as f:\n",
    "    f.write(patched_utils_content)\n",
    "print(\"Patched notebook_utils.py with latest local version.\")\n",
    "\n",
    "# --- 4. Setup External Tools & Config ---\n",
    "repo_path = os.path.abspath(\"FrankPEPstein\")\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "from scripts import notebook_utils\n",
    "\n",
    "# DRIVE CONFIGURATION: Enter your File IDs here\n",
    "drive_ids = {\n",
    "    \"adfr_id\": \"1gmRj8mva84-JB7UXUcQfB3Ziw_nwwdox\",       # ADFRsuite_x86_64Linux_1.0.tar.gz\n",
    "    \"db_id\": \"1a4GoZ1ZT-DNYMyvVtKJukNdF6TAaLJU5\",    # minipockets_..._curated-db.tar.gz\n",
    "    \"dict_id\": \"1nrwSUof0lox9fp8Ow5EICIN9u0lglu7U\"      # reduce_wwPDB_het_dict.tar.gz\n",
    "}\n",
    "\n",
    "print(\"Setting up external tools...\")\n",
    "notebook_utils.setup_external_tools(drive_ids)\n",
    "\n",
    "print(\"Configuring Modeller...\")\n",
    "notebook_utils.configure_modeller()\n",
    "\n",
    "print(\"Setup Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c314d",
   "metadata": {},
   "source": [
    "## 1. Input Data: Upload Receptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd528725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Upload your Receptor PDB file (e.g., receptor.pdb)\")\n",
    "uploaded = files.upload()\n",
    "receptor_filename = list(uploaded.keys())[0]\n",
    "print(f\"Receptor uploaded: {receptor_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46583dd",
   "metadata": {},
   "source": [
    "## 2. Pocket Detection (fpocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Run fpocket and Visualize\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Run fpocket\n",
    "# Note: fpocket should be in the path thanks to Step 0.2\n",
    "print(f\"Running fpocket on {receptor_filename}...\")\n",
    "try:\n",
    "    subprocess.run(f\"fpocket -f {receptor_filename}\", shell=True, check=True)\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Error running fpocket. Checking path...\")\n",
    "    print(subprocess.getoutput(\"which fpocket\"))\n",
    "    raise\n",
    "\n",
    "output_folder = f\"{receptor_filename}_out\"\n",
    "if os.path.exists(output_folder):\n",
    "    print(\"fpocket finished successfully.\")\n",
    "    pockets_dir = os.path.join(output_folder, \"pockets\")\n",
    "    pockets = [f for f in os.listdir(pockets_dir) if f.endswith(\".pdb\")]\n",
    "    print(f\"Found {len(pockets)} pockets.\")\n",
    "else:\n",
    "    print(\"Error: fpocket output folder not found.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
